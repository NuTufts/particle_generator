{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for evaluation of a trained AutoEncoder Model\n",
    "- This notebook is step 1 of 3 in setting up a model pipeline for generating particle decay event images\n",
    "- The notebook is broken up into the following components:\n",
    "    - Loss evaluation and plotting\n",
    "        - The loss for the entire training cycle is plotted\n",
    "        - The loss curves for each of the model checkpoints between 600 and 1000 are plotted\n",
    "            - We compute the average loss value over 10k test samples and 10k training samples\n",
    "    - An appropriately generalizable Decoder is chosen based on the smalled difference in MSE value from the previous evaluation step\n",
    "    - Sets of sample images are generated for that checkpoint using test data in order to assess image reconstruction quality\n",
    "    - A set of code vector targets is generated using that model checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Files from full path on Meitner Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/kseuro/Kai/deeplearnphysics/pytorch/particle_generator/')\n",
    "\n",
    "# Meitner Machine\n",
    "import ae\n",
    "import conv_ae\n",
    "import utils\n",
    "from dataloader import LArCV_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the GPU to be used for model evaluation\n",
    "- On Meitner, GPU 1 is the best option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the root path of the AutoEncoder Experiments Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_root = \"/media/hdd1/kai/particle_generator/experiments/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the model class and append to the experiment root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = {'mlp': 'mlp_ae/', 'conv':'conv_ae/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"larcv_ae/\" + model_class['conv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_root += model_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all the experiments in the exp_root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_paths = []\n",
    "for path in os.listdir(exp_root):\n",
    "    exp_paths.append(os.path.join(exp_root, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\n",
      "0: conv_ae_128_4-4-4 \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "1: conv_ae_128_20-4-4 \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "2: conv_ae_64_12-4-4 \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "3: conv_ae_64_4-4-4 \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "4: conv_ae_64_1000-epochs \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "5: conv_ae_128_32-8-8-code-dim \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "6: conv_ae_256_102-4-4 \n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*60)\n",
    "for i in range(len(exp_paths)):\n",
    "    exp_name = exp_paths[i].split('/')[-1]\n",
    "    print(\"\\n{}:\".format(str(i)), exp_name, '\\n')\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the experiment for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = exp_paths[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment path set as: \n",
      "/media/hdd1/kai/particle_generator/experiments/larcv_ae/conv_ae/conv_ae_64_12-4-4/\n"
     ]
    }
   ],
   "source": [
    "# Create the full path to the experiment\n",
    "exp_path = os.path.join(exp_root, exp_dir) + \"/\"\n",
    "print(\"Experiment path set as: \\n{}\".format(exp_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path from where to load the model weights\n",
    "weights_dir = \"weights/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model configuration information from the config.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config csv as a dict\n",
    "config_csv = exp_path + \"config.csv\"\n",
    "config_df = pd.read_csv(config_csv, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model architecture from config df\n",
    "num_epochs = int(config_df[config_df['Unnamed: 0'].str.contains(\"epochs\")==True]['0'].values.item())\n",
    "n_layers = int(config_df[config_df['Unnamed: 0'].str.contains(\"n_layers\")==True]['0'].values.item())\n",
    "l_dim    = int(config_df[config_df['Unnamed: 0'].str.contains(\"l_dim\")==True]['0'].values.item())\n",
    "depth    = int(config_df[config_df['Unnamed: 0'].str.contains(\"depth\")==True]['0'].values.item())\n",
    "im_size  = int(config_df[config_df['Unnamed: 0'].str.contains(\"dataset\")==True]['0'].values.item())**2\n",
    "im_dim   = int(np.sqrt(im_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the layer dimensions for the AutoEncoder\n",
    "- TODO: Need to add function that deals with an AutoEncoder Model trained on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up AE layer sizes\n",
    "if 'mlp' in exp_path:    \n",
    "    base = [256] \n",
    "\n",
    "    # Compute encoder sizes\n",
    "    sizes = lambda: [ (yield 2**i) for i in range(n_layers) ]\n",
    "    enc_sizes = base * n_layers\n",
    "    enc_sizes = [a*b for a,b in zip(enc_sizes, [*sizes()])][::-1]\n",
    "\n",
    "    # Update kwarg dicts\n",
    "    # Decoder is the reverse of the encoder\n",
    "    ae_kwargs = {'enc_sizes' : enc_sizes, 'l_dim' : l_dim, 'im_size' : im_size, 'dec_sizes' : enc_sizes[::-1]}\n",
    "else:\n",
    "    # Compute the depth of the feature maps, based on the number of\n",
    "    # specified layers. If depth is not divisibe by 4, warn\n",
    "    depth   = [depth] * n_layers\n",
    "    divisor = lambda: [ (yield 2**i) for i in range(n_layers) ]\n",
    "    depth   = [a//b for a,b in zip(depth, [*divisor()])][::-1]\n",
    "        \n",
    "    # Update kwarg dicts\n",
    "    # Decoder is the reverse of the encoder\n",
    "    ae_kwargs = {'enc_depth':[1] + depth, 'dec_depth':depth[1:len(depth)][::-1] + [1],'l_dim':l_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model l_dim: 12\n",
      "Encoder depth: [1, 4, 8, 16, 32]\n",
      "Decoder depth: [32, 16, 8, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model l_dim: {}\".format(l_dim))\n",
    "print(\"Encoder depth: {}\".format(ae_kwargs['enc_depth']))\n",
    "print(\"Decoder depth: {}\".format(ae_kwargs['dec_depth']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Model loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up tracking of MSE evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model from Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of checkpoint files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path  = exp_path + weights_dir\n",
    "checkpoint_names = []\n",
    "for file in os.listdir(checkpoint_path):\n",
    "    checkpoint_names.append(os.path.join(checkpoint_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wish to save a list of labels for ease of plot labelling later\n",
    "checkpoint_name_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\n",
      "0: best_conv_ae_ep_650.tar \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "1: best_conv_ae_ep_600.tar \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "2: best_conv_ae_ep_999.tar \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "3: best_conv_ae_ep_700.tar \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "4: best_conv_ae_ep_850.tar \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "5: best_conv_ae_ep_900.tar \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "6: best_conv_ae_ep_950.tar \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "7: best_conv_ae_ep_750.tar \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "8: best_conv_ae_ep_800.tar \n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*60)\n",
    "for i in range(len(checkpoint_names)):\n",
    "    name = checkpoint_names[i].split('/')[-1]\n",
    "    checkpoint_name_labels.append(name)\n",
    "    print(\"\\n{}:\".format(str(i)), name, '\\n')\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the checkpoint you wish to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "current_checkpoint = checkpoint_names[index]\n",
    "current_checkpoint_label = checkpoint_name_labels[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the checkpoint file using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model checkpoint\n",
    "# Keys: ['state_dict', 'epoch', 'optimizer']\n",
    "checkpoint = torch.load(current_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model on GPU\n",
    "if 'mlp' in exp_path:\n",
    "    model = ae.AutoEncoder(**ae_kwargs).to(device)\n",
    "else:\n",
    "    model = conv_ae.ConvAutoEncoder(**ae_kwargs).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model's state dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model's state dictionary\n",
    "# Note: The IncompatibleKeys(missing_keys=[], unexpected_keys=[]) message indicates that\n",
    "#       there were no problems in loading the state dictionary. Bit confusing...\n",
    "model.load_state_dict(checkpoint['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put model in training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvAutoEncoder(\n",
       "  (encoder): ConvEncoder(\n",
       "    (conv_blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (last): Conv2d(32, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (decoder): ConvDecoder(\n",
       "    (deconv_blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(12, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): ConvTranspose2d(8, 1, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the PyTorch Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the paths to the test data and reference training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 test data will be loaded from: \n",
      "/media/hdd1/kai/particle_generator/larcv_data/test/larcv_png_64/\n"
     ]
    }
   ],
   "source": [
    "test_data = \"/media/hdd1/kai/particle_generator/larcv_data/test/larcv_png_{}/\".format(im_dim)\n",
    "num_test_ex = sum( [len(examples) for _, _, examples in os.walk(test_data)] )\n",
    "print(\"{} test data will be loaded from: \\n{}\".format(num_test_ex, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 reference training data will be loaded from: \n",
      "/media/hdd1/kai/particle_generator/larcv_data/train/train_reference/larcv_png_64/\n"
     ]
    }
   ],
   "source": [
    "train_data = \"/media/hdd1/kai/particle_generator/larcv_data/train/train_reference/larcv_png_{}/\".format(im_dim)\n",
    "num_train_ex = sum( [len(examples) for _, _, examples in os.walk(train_data)] )\n",
    "print(\"{} reference training data will be loaded from: \\n{}\".format(num_train_ex, train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup two instances of a dataloader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_kwargs = {'num_workers' : 2, 'batch_size': 1, 'shuffle': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Compose' object has no attribute 'Compose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-7756c2160d20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Compose' object has no attribute 'Compose'"
     ]
    }
   ],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5],[0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image conversion flag is: L\n",
      "Images will be loaded from subfolder of: /media/hdd1/kai/particle_generator/larcv_data/test/larcv_png_64/\n"
     ]
    }
   ],
   "source": [
    "test_dataset    = LArCV_loader(root = test_data,  transforms = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, **loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image conversion flag is: L\n",
      "Images will be loaded from subfolder of: /media/hdd1/kai/particle_generator/larcv_data/test/larcv_png_64/\n",
      "Image conversion flag is: L\n",
      "Images will be loaded from subfolder of: /media/hdd1/kai/particle_generator/larcv_data/train/train_reference/larcv_png_64/\n"
     ]
    }
   ],
   "source": [
    "train_dataset   = LArCV_loader(root = train_data, transforms = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, **loader_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Loss Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full loss curve for entire training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_csv = exp_path + \"losses.csv\"\n",
    "losses_df = pd.read_csv(losses_csv, delimiter = \",\")\n",
    "losses = np.asarray(losses_df['ae_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average loss per epoch based based on loss array len\n",
    "step = int(len(losses) / num_epochs)\n",
    "new_losses = []\n",
    "for i in range(0, len(losses), step):\n",
    "    new_losses.append( sum(losses[i:i+step]) / step )\n",
    "new_losses = np.asarray(new_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the plot title\n",
    "if 'mlp' in exp_path:\n",
    "    title = \"MLP AutoEncoder Training Loss\" \n",
    "else:\n",
    "    title = \"Convolutional AutoEncoder Training Loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the experiment label\n",
    "if 'mlp' in exp_path:\n",
    "    label = \"{}x{} Dataset | {} Dimensional Code Vector\".format(im_dim, im_dim, l_dim)\n",
    "else:\n",
    "    label = \"{}x{} Dataset | {}x{}x{} Dimensional Code Volume\".format(im_dim, im_dim, l_dim, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the file name for saving\n",
    "if 'mlp' in exp_path:\n",
    "    save_file = \"training_loss_MLP_AE_{}_dataset_{}_l-dim.png\".format(im_dim, l_dim)\n",
    "else:\n",
    "    save_file = \"training_loss_Conv_AE_{}_dataset_{}-{}-{}_code-volume.png\".format(im_dim, l_dim, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Plot the losses against the number of epochs\n",
    "fig, axes = plt.subplots(1,1)\n",
    "fig.suptitle(title)\n",
    "\n",
    "axes.set_title(label, fontsize=\"small\")\n",
    "axes.set_xlabel(\"Epoch Number\")\n",
    "axes.set_ylabel(\"Loss Value\")\n",
    "\n",
    "# Plot data\n",
    "axes.plot(np.arange(0, num_epochs), new_losses)\n",
    "\n",
    "# Generate and save image\n",
    "plt.savefig(save_file, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
