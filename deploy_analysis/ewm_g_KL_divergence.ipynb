{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from scipy import special as S\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial import distance\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/kseuro/Kai/deeplearnphysics/pytorch/particle_generator/')\n",
    "\n",
    "# Meitner Machine\n",
    "import ewm\n",
    "import utils\n",
    "from dataloader import BottleLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_root = \"/media/hdd1/kai/particle_generator/experiments/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = False\n",
    "if mlp:\n",
    "    EWM_root = exp_root + 'ewm_models/mlp_ewm/'\n",
    "else:\n",
    "    EWM_root = exp_root + 'ewm_models/conv_ewm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to model weights\n",
    "weights_dir = \"weights/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EWM_paths = []\n",
    "# EWM_root += 'evaluated_models/'\n",
    "for path in os.listdir(EWM_root):\n",
    "    EWM_paths.append(os.path.join(EWM_root, path))\n",
    "\n",
    "print(\"-\"*60)\n",
    "for i in range(len(EWM_paths)):\n",
    "    EWM_name = EWM_paths[i].split('/')[-1]\n",
    "    print(\"\\n Exp_{}:\".format(str(i)), EWM_name, '\\n')\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EWM_dir = EWM_paths[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the full path to the EWM model\n",
    "EWM_path = os.path.join(EWM_root, EWM_dir) + \"/\"\n",
    "print(\"Path to EWM Generator Model set as: \\n{}\".format(EWM_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_csv = EWM_path + \"config.csv\"\n",
    "config_df = pd.read_csv(config_csv, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model architecture from config df\n",
    "n_layers = int(config_df[config_df['Unnamed: 0'].str.contains(\"n_layers\")==True]['0'].values.item())\n",
    "n_hidden = int(config_df[config_df['Unnamed: 0'].str.contains(\"n_hidden\")==True]['0'].values.item())\n",
    "l_dim    = int(config_df[config_df['Unnamed: 0'].str.contains(\"l_dim\")==True]['0'].values.item())\n",
    "im_size  = int(config_df[config_df['Unnamed: 0'].str.contains(\"dataset\")==True]['0'].values.item())\n",
    "z_dim    = int(config_df[config_df['Unnamed: 0'].str.contains(\"z_dim\")==True]['0'].values.item())\n",
    "print(\"{} Layer model with {} hidden units per layer\".format(n_layers, n_hidden))\n",
    "print('Bottleneck dimension (unrolled): {}'.format(l_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model kwargs\n",
    "fc_sizes = [n_hidden] * n_layers\n",
    "ewm_kwargs = { 'z_dim':z_dim, 'fc_sizes':fc_sizes, 'n_out':l_dim }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generator on GPU\n",
    "G = ewm.ewm_G(**ewm_kwargs).to(device)\n",
    "G.weights_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get checkpoint name(s)\n",
    "EWM_checkpoint_path  = EWM_path + weights_dir\n",
    "EWM_checkpoint_names = []\n",
    "for file in os.listdir(EWM_checkpoint_path):\n",
    "    EWM_checkpoint_names.append(os.path.join(EWM_checkpoint_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*60)\n",
    "for i in range(len(EWM_checkpoint_names)):\n",
    "    name = EWM_checkpoint_names[i].split('/')[-1]\n",
    "    print(\"\\n {} :\".format(str(i)), name, '\\n')\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the checkpoint you want\n",
    "EWM_checkpoint = EWM_checkpoint_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model checkpoint\n",
    "# Keys: ['state_dict', 'epoch', 'optimizer']\n",
    "checkpoint = torch.load(EWM_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model's state dictionary\n",
    "# Note: The IncompatibleKeys(missing_keys=[], unexpected_keys=[]) message indicates that\n",
    "#       there were no problems in loading the state dictionary. Bit confusing...\n",
    "G.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the model in evaluation mode\n",
    "G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'ewm_target':'conv', 'num_workers':0, 'batch_size':1, 'shuffle':False, 'drop_last':False,\n",
    "          'vec_root':'/media/hdd1/kai/particle_generator/code_vectors_test/', 'dataset':64, 'l_dim':l_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = utils.get_test_loader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_vectors = []; t_vectors = []; epsilon = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, target_vec in enumerate(test_loader):\n",
    "    \n",
    "    # Get output from the generator model\n",
    "    z_rand = torch.randn(config['batch_size'], 1, 100).to(device)\n",
    "    code_vec = G(z_rand).view(-1).to(device)\n",
    "    \n",
    "    # Append vector from generator function to list\n",
    "    g_vectors.append(code_vec.detach().cpu().numpy())\n",
    "    \n",
    "    # Append target vector to list\n",
    "    t_vectors.append(target_vec.view(-1).detach().cpu().numpy())\n",
    "    \n",
    "    del code_vec\n",
    "    del target_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SciPi Entropy Function](http://scipy.github.io/devdocs/generated/scipy.stats.entropy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_vector = np.array([g for g in g_vectors]).flatten() + epsilon\n",
    "t_vector = np.array([t for t in t_vectors]).flatten() + epsilon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
