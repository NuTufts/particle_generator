{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from scipy import special as S\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial import distance\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/kseuro/Kai/deeplearnphysics/pytorch/particle_generator/')\n",
    "\n",
    "# Meitner Machine\n",
    "import ewm\n",
    "import utils\n",
    "from dataloader import BottleLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_root = \"/media/hdd1/kai/particle_generator/experiments/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = False\n",
    "if mlp:\n",
    "    EWM_root = exp_root + 'ewm_models/mlp_ewm/'\n",
    "else:\n",
    "    EWM_root = exp_root + 'ewm_models/conv_ewm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to model weights\n",
    "weights_dir = \"weights/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\n",
      " Exp_0: ewm_64_192 \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      " Exp_1: 02-21-2020_10-40-28_ewm_20_epochs_Code_Vectors_64_384 \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      " Exp_2: ewm_128_320 \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      " Exp_3: ewm_nonsense2_64-384 \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      " Exp_4: ewm_nonsense_64_384 \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      " Exp_5: ewm_256_6528 \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      " Exp_6: evaluated_models \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      " Exp_7: ewm_256_1632 \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      " Exp_8: ewm_nonsense3_64-384 \n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "EWM_paths = []\n",
    "for path in os.listdir(EWM_root):\n",
    "    EWM_paths.append(os.path.join(EWM_root, path))\n",
    "\n",
    "print(\"-\"*60)\n",
    "for i in range(len(EWM_paths)):\n",
    "    EWM_name = EWM_paths[i].split('/')[-1]\n",
    "    print(\"\\n Exp_{}:\".format(str(i)), EWM_name, '\\n')\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EWM_dir = EWM_paths[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to EWM Generator Model set as: \n",
      "/media/hdd1/kai/particle_generator/experiments/ewm_models/conv_ewm/02-21-2020_10-40-28_ewm_20_epochs_Code_Vectors_64_384/\n"
     ]
    }
   ],
   "source": [
    "# Create the full path to the EWM model\n",
    "EWM_path = os.path.join(EWM_root, EWM_dir) + \"/\"\n",
    "print(\"Path to EWM Generator Model set as: \\n{}\".format(EWM_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_csv = EWM_path + \"config.csv\"\n",
    "config_df = pd.read_csv(config_csv, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Layer model with 512 hidden units per layer\n"
     ]
    }
   ],
   "source": [
    "# Get the model architecture from config df\n",
    "n_layers = int(config_df[config_df['Unnamed: 0'].str.contains(\"n_layers\")==True]['0'].values.item())\n",
    "n_hidden = int(config_df[config_df['Unnamed: 0'].str.contains(\"n_hidden\")==True]['0'].values.item())\n",
    "l_dim    = int(config_df[config_df['Unnamed: 0'].str.contains(\"l_dim\")==True]['0'].values.item())\n",
    "im_size  = int(config_df[config_df['Unnamed: 0'].str.contains(\"dataset\")==True]['0'].values.item())\n",
    "z_dim    = int(config_df[config_df['Unnamed: 0'].str.contains(\"z_dim\")==True]['0'].values.item())\n",
    "print(\"{} Layer model with {} hidden units per layer\".format(n_layers, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model kwargs\n",
    "fc_sizes = [n_hidden] * n_layers\n",
    "ewm_kwargs = { 'z_dim':z_dim, 'fc_sizes':fc_sizes, 'n_out':l_dim }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generator on GPU\n",
    "G = ewm.ewm_G(**ewm_kwargs).to(device)\n",
    "G.weights_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get checkpoint name(s)\n",
    "EWM_checkpoint_path  = EWM_path + weights_dir\n",
    "EWM_checkpoint_names = []\n",
    "for file in os.listdir(EWM_checkpoint_path):\n",
    "    EWM_checkpoint_names.append(os.path.join(EWM_checkpoint_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\n",
      " 0 : best_ewm_ep_0.tar \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      " 1 : best_ewm_ep_19.tar \n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*60)\n",
    "for i in range(len(EWM_checkpoint_names)):\n",
    "    name = EWM_checkpoint_names[i].split('/')[-1]\n",
    "    print(\"\\n {} :\".format(str(i)), name, '\\n')\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the checkpoint you want\n",
    "EWM_checkpoint = EWM_checkpoint_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model checkpoint\n",
    "# Keys: ['state_dict', 'epoch', 'optimizer']\n",
    "checkpoint = torch.load(EWM_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model's state dictionary\n",
    "# Note: The IncompatibleKeys(missing_keys=[], unexpected_keys=[]) message indicates that\n",
    "#       there were no problems in loading the state dictionary. Bit confusing...\n",
    "G.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ewm_G(\n",
       "  (fc): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=384, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the model in evaluation mode\n",
    "G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'ewm_target':'conv', 'num_workers':0, 'batch_size':1, 'shuffle':False, 'drop_last':False,\n",
    "          'vec_root':'/media/hdd1/kai/particle_generator/code_vectors_test/', 'dataset':64, 'l_dim':l_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code-Target examples will be loaded from subfolder of: \n",
      "/media/hdd1/kai/particle_generator/code_vectors_test/conv_ae/code_vectors_64_384/\n"
     ]
    }
   ],
   "source": [
    "test_loader = utils.get_test_loader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_vectors = []; t_vectors = []; epsilon = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, test_vec in enumerate(test_loader):\n",
    "    \n",
    "    # Get output from the generator model\n",
    "    z_rand = torch.randn(config['batch_size'], 1, 100).to(device)\n",
    "    code_vec = G(z_rand).view(-1).to(device)\n",
    "    g_vectors.append(code_vec.detach().cpu().numpy())\n",
    "    \n",
    "    # Keep test vec\n",
    "    test_vec = test_vec.view(-1).detach().cpu().numpy()\n",
    "    t_vectors.append(test_vec)\n",
    "    \n",
    "    del code_vec\n",
    "    del test_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SciPi Entropy Function](http://scipy.github.io/devdocs/generated/scipy.stats.entropy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_vectors = np.array([g for g in g_vectors]).flatten() + epsilon\n",
    "t_vectors = np.array([t for t in t_vectors]).flatten() + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.nonzero(g_vectors)[0]) == len(g_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.nonzero(t_vectors)[0]) == len(t_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kseuro/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(_p * np.log(_p / _q) for _p, _q in zip(g_vectors, t_vectors) if _p != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = entropy(pk=t_vectors, qk=g_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3840000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.nonzero(g_vectors)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div = S.kl_div(g_vectors, t_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([inf, inf, inf, ..., inf, inf, inf], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01137161,  0.07320309,  0.0429039 , ...,  0.3619461 ,\n",
       "        0.16585541,  0.04455185], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_vectors - t_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = distance.jensenshannon(t_vectors, g_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
